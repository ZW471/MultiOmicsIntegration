{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T10:54:51.775346Z",
     "start_time": "2025-03-08T10:54:34.404964Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch import Tensor\n",
    "from torch_geometric.typing import Adj\n",
    "\n",
    "from datasets.preprocess import remove_lsi_key, preprocess\n",
    "import scanpy as sc\n",
    "\n",
    "modalities = [\"adt\", \"RNA\", 'atac']\n",
    "\n",
    "datasets = {}\n",
    "\n",
    "for modality in modalities:\n",
    "    try:\n",
    "        datasets[modality] = preprocess(modality, f\"../datasets/data/processed/PBMC-DOGMA_{modality}.h5ad\", n_pcs=100)\n",
    "    except ValueError:\n",
    "        remove_lsi_key(f\"../datasets/data/processed/PBMC-DOGMA_{modality}.h5ad\")\n",
    "        datasets[modality] = preprocess(modality, f\"../datasets/data/processed/PBMC-DOGMA_{modality}.h5ad\", n_pcs=100)\n",
    "datasets"
   ],
   "id": "af6f4299efb06978",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wzy66\\anaconda3\\envs\\MultiOmicsIntegration\\Lib\\site-packages\\scanpy\\preprocessing\\_normalization.py:234: UserWarning: Some cells have zero counts\n",
      "  warn(UserWarning(\"Some cells have zero counts\"))\n",
      "C:\\Users\\wzy66\\anaconda3\\envs\\MultiOmicsIntegration\\Lib\\site-packages\\scanpy\\preprocessing\\_highly_variable_genes.py:251: UserWarning: If you pass `n_top_genes`, all cutoffs are ignored.\n",
      "  warnings.warn(msg, UserWarning)\n",
      "C:\\Users\\wzy66\\anaconda3\\envs\\MultiOmicsIntegration\\Lib\\site-packages\\scanpy\\preprocessing\\_scale.py:318: UserWarning: Received a view of an AnnData. Making a copy.\n",
      "  view_to_actual(adata)\n",
      "C:\\Users\\wzy66\\anaconda3\\envs\\MultiOmicsIntegration\\Lib\\site-packages\\scanpy\\preprocessing\\_normalization.py:234: UserWarning: Some cells have zero counts\n",
      "  warn(UserWarning(\"Some cells have zero counts\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'adt': AnnData object with n_obs × n_vars = 13763 × 210\n",
       "     obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'stim', 'celltype', 'nCount_atac', 'nFeature_atac', 'nCount_adt', 'nFeature_adt'\n",
       "     var: 'features', 'mean', 'std'\n",
       "     uns: 'pca'\n",
       "     obsm: 'X_apca', 'X_apca.raw', 'X_pca'\n",
       "     varm: 'APCA.RAW', 'PCs',\n",
       " 'RNA': AnnData object with n_obs × n_vars = 13763 × 300\n",
       "     obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'stim', 'celltype', 'nCount_atac', 'nFeature_atac', 'nCount_adt', 'nFeature_adt'\n",
       "     var: 'vst.mean', 'vst.variance', 'vst.variance.expected', 'vst.variance.standardized', 'vst.variable', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std'\n",
       "     uns: 'log1p', 'hvg', 'pca'\n",
       "     obsm: 'X_rpca', 'X_rpca.raw', 'X_pca'\n",
       "     varm: 'RPCA.RAW', 'PCs',\n",
       " 'atac': AnnData object with n_obs × n_vars = 13763 × 5000\n",
       "     obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'stim', 'celltype', 'nCount_atac', 'nFeature_atac', 'nCount_adt', 'nFeature_adt'\n",
       "     var: 'count', 'percentile', 'vst.mean', 'vst.variance', 'vst.variance.expected', 'vst.variance.standardized', 'vst.variable', 'mean', 'std'\n",
       "     uns: 'log1p', 'pca'\n",
       "     obsm: 'X_lsi', 'X_lsi.raw', 'X_pca'\n",
       "     varm: 'PCs'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T10:55:08.228631Z",
     "start_time": "2025-03-08T10:55:07.690632Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "X = {m: torch.tensor(datasets[m].obsm['X_pca'], dtype=torch.float, device=device) for m in modalities}\n",
    "for k, v in X.items():\n",
    "    print(k, v.shape)"
   ],
   "id": "c56b99a56ea5ff47",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adt torch.Size([13763, 100])\n",
      "RNA torch.Size([13763, 100])\n",
      "atac torch.Size([13763, 100])\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# cell_seq_rep -> seq_sim -> cell",
   "id": "2f56d6781ce3b551"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T10:55:12.709871Z",
     "start_time": "2025-03-08T10:55:11.685774Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch_cluster import knn_graph\n",
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "edge_indices = {}\n",
    "for m in modalities:\n",
    "    edge_indices[m] = knn_graph(\n",
    "        X[m],\n",
    "        k=min(X[m].shape[0] // 20, 50),\n",
    "        cosine=True,\n",
    "        num_workers=16\n",
    "    )\n",
    "edge_indices"
   ],
   "id": "52d28ad9f6a25906",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adt': tensor([[ 2917,   844,  2871,  ..., 12844, 12267,  9163],\n",
       "         [    0,     0,     0,  ..., 13762, 13762, 13762]], device='cuda:0'),\n",
       " 'RNA': tensor([[ 2574,  9294,  4927,  ..., 12470, 12342,   480],\n",
       "         [    0,     0,     0,  ..., 13762, 13762, 13762]], device='cuda:0'),\n",
       " 'atac': tensor([[ 6431,  5201,  7867,  ...,  2002,  2193,  3477],\n",
       "         [    0,     0,     0,  ..., 13762, 13762, 13762]], device='cuda:0')}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T10:55:29.521683Z",
     "start_time": "2025-03-08T10:55:29.203864Z"
    }
   },
   "cell_type": "code",
   "source": [
    "E = {}\n",
    "for m in modalities:\n",
    "    src, tgt = edge_indices[m]\n",
    "    # E[m] = torch.bmm(X[m][src].unsqueeze(1), X[m][tgt].unsqueeze(-1)).squeeze()\n",
    "    E[m] = torch.norm(X[m][src] - X[m][tgt], dim=1)\n",
    "E"
   ],
   "id": "4466c6f55a4612b3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adt': tensor([10.4106, 11.0088, 10.1860,  ..., 11.6050, 12.9893, 11.3765],\n",
       "        device='cuda:0'),\n",
       " 'RNA': tensor([ 0.0394,  0.3796,  0.6669,  ...,  6.5936, 25.8649,  6.7953],\n",
       "        device='cuda:0'),\n",
       " 'atac': tensor([2.4650, 2.5006, 2.5179,  ..., 2.1866, 2.1866, 2.1866], device='cuda:0')}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T10:56:01.175558Z",
     "start_time": "2025-03-08T10:56:01.171557Z"
    }
   },
   "cell_type": "code",
   "source": [
    "C = torch.cat([X[m] for m in modalities], dim=1)\n",
    "C.shape"
   ],
   "id": "b27e83315e8bb20c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13763, 300])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T11:15:43.696207Z",
     "start_time": "2025-03-08T11:15:42.613945Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch_geometric.data import HeteroData\n",
    "\n",
    "# (1) Assign attributes after initialization,\n",
    "data = HeteroData()\n",
    "\n",
    "data['cell'].x = C\n",
    "data['cell', 'similar_to', 'cell'].edge_index = knn_graph(\n",
    "    C,\n",
    "    k=min(100, C.shape[0] // 200),\n",
    "    cosine=True,\n",
    "    num_workers=16\n",
    ")\n",
    "\n",
    "for m in modalities:\n",
    "    data[m].x = X[m]\n",
    "    data[m, \"similar_to\", m].edge_index = edge_indices[m]\n",
    "    data[m, \"belongs_to\", \"cell\"].edge_index = torch.stack([torch.arange(C.shape[0]), torch.arange(C.shape[0])], dim=0)\n",
    "    data[m, \"similar_to\", m].e = E[m] if len(E[m].shape) > 1 else E[m].unsqueeze(-1)\n",
    "data"
   ],
   "id": "5a7ed58222cab9ab",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  cell={ x=[13763, 300] },\n",
       "  adt={ x=[13763, 100] },\n",
       "  RNA={ x=[13763, 100] },\n",
       "  atac={ x=[13763, 100] },\n",
       "  (cell, similar_to, cell)={ edge_index=[2, 935884] },\n",
       "  (adt, similar_to, adt)={\n",
       "    edge_index=[2, 688150],\n",
       "    e=[688150, 1],\n",
       "  },\n",
       "  (adt, belongs_to, cell)={ edge_index=[2, 13763] },\n",
       "  (RNA, similar_to, RNA)={\n",
       "    edge_index=[2, 688150],\n",
       "    e=[688150, 1],\n",
       "  },\n",
       "  (RNA, belongs_to, cell)={ edge_index=[2, 13763] },\n",
       "  (atac, similar_to, atac)={\n",
       "    edge_index=[2, 688150],\n",
       "    e=[688150, 1],\n",
       "  },\n",
       "  (atac, belongs_to, cell)={ edge_index=[2, 13763] }\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T14:30:23.571778Z",
     "start_time": "2025-03-08T14:30:23.463806Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch_geometric.loader import NeighborLoader\n",
    "\n",
    "if 'train_mask' not in data['cell']:\n",
    "    data['cell']['train_mask'] = torch.ones(data['cell'].x.size(0), dtype=torch.bool)\n",
    "\n",
    "# Define the neighbor sampling configuration.\n",
    "# For each edge type, you specify a list of numbers representing the number of neighbors\n",
    "# to sample at each layer (e.g., [first_hop, second_hop]).\n",
    "sampler = NeighborLoader(\n",
    "    data,\n",
    "    num_neighbors={\n",
    "        ('adt', 'similar_to', 'adt'): [15, 10],\n",
    "        ('adt', 'belongs_to', 'cell'): [1, 0],\n",
    "        ('RNA', 'similar_to', 'RNA'): [15, 10],\n",
    "        ('RNA', 'belongs_to', 'cell'): [1, 0],\n",
    "        ('atac', 'similar_to', 'atac'): [15, 10],\n",
    "        ('atac', 'belongs_to', 'cell'): [1, 0],\n",
    "        ('cell', 'similar_to', 'cell'): [8, 4],\n",
    "    },\n",
    "    input_nodes=('cell', data['cell']['train_mask']),\n",
    "    batch_size=2048,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "sample = next(iter(sampler))\n",
    "sample"
   ],
   "id": "5e9f2440ff371b4e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  cell={\n",
       "    x=[10847, 300],\n",
       "    train_mask=[10847],\n",
       "    n_id=[10847],\n",
       "    num_sampled_nodes=[3],\n",
       "    input_id=[2048],\n",
       "    batch_size=2048,\n",
       "  },\n",
       "  adt={\n",
       "    x=[9989, 100],\n",
       "    n_id=[9989],\n",
       "    num_sampled_nodes=[3],\n",
       "  },\n",
       "  RNA={\n",
       "    x=[7924, 100],\n",
       "    n_id=[7924],\n",
       "    num_sampled_nodes=[3],\n",
       "  },\n",
       "  atac={\n",
       "    x=[8459, 100],\n",
       "    n_id=[8459],\n",
       "    num_sampled_nodes=[3],\n",
       "  },\n",
       "  (cell, similar_to, cell)={\n",
       "    edge_index=[2, 42500],\n",
       "    e_id=[42500],\n",
       "    num_sampled_edges=[2],\n",
       "  },\n",
       "  (adt, similar_to, adt)={\n",
       "    edge_index=[2, 20480],\n",
       "    e=[20480, 1],\n",
       "    e_id=[20480],\n",
       "    num_sampled_edges=[2],\n",
       "  },\n",
       "  (adt, belongs_to, cell)={\n",
       "    edge_index=[2, 2048],\n",
       "    e_id=[2048],\n",
       "    num_sampled_edges=[2],\n",
       "  },\n",
       "  (RNA, similar_to, RNA)={\n",
       "    edge_index=[2, 20480],\n",
       "    e=[20480, 1],\n",
       "    e_id=[20480],\n",
       "    num_sampled_edges=[2],\n",
       "  },\n",
       "  (RNA, belongs_to, cell)={\n",
       "    edge_index=[2, 2048],\n",
       "    e_id=[2048],\n",
       "    num_sampled_edges=[2],\n",
       "  },\n",
       "  (atac, similar_to, atac)={\n",
       "    edge_index=[2, 20480],\n",
       "    e=[20480, 1],\n",
       "    e_id=[20480],\n",
       "    num_sampled_edges=[2],\n",
       "  },\n",
       "  (atac, belongs_to, cell)={\n",
       "    edge_index=[2, 2048],\n",
       "    e_id=[2048],\n",
       "    num_sampled_edges=[2],\n",
       "  }\n",
       ")"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 113
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T14:30:25.113785Z",
     "start_time": "2025-03-08T14:30:24.881510Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.nn as nn\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch.nn import Linear\n",
    "\n",
    "class IntraModalityMP(MessagePassing):\n",
    "    def __init__(self, node_dim, edge_attr_dim, hidden_dims):\n",
    "        super(IntraModalityMP, self).__init__(aggr='add')\n",
    "        # Fully connected layer to compute edge messages from concatenated features:\n",
    "        # concatenated features have size: 2 * in_channels + edge_attr_dim\n",
    "        self.fc_message = nn.Linear(2 * node_dim, hidden_dims)\n",
    "        # Fully connected layer to update node features after aggregation\n",
    "        self.fc_update = nn.Linear(hidden_dims, hidden_dims)\n",
    "        # Optionally, include a non-linear activation\n",
    "        self.activation = nn.SiLU()\n",
    "\n",
    "        self.edge_gate = nn.Sequential(\n",
    "            nn.Linear(edge_attr_dim, edge_attr_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(edge_attr_dim, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x (Tensor): Node features with shape [num_nodes, in_channels].\n",
    "            edge_index (LongTensor): Graph connectivity in COO format [2, num_edges].\n",
    "            edge_attr (Tensor): Edge attributes with shape [num_edges, edge_attr_dim].\n",
    "        Returns:\n",
    "            Tensor: Updated node features with shape [num_nodes, out_channels].\n",
    "        \"\"\"\n",
    "        return self.propagate(edge_index, x=x, edge_attr=edge_attr)\n",
    "\n",
    "    def message(self, x_i, x_j, edge_attr):\n",
    "        \"\"\"\n",
    "        For each edge, concatenate target node feature (x_i), source node feature (x_j),\n",
    "        and edge attribute (edge_attr), then compute the edge message.\n",
    "        \"\"\"\n",
    "        # Concatenate features from the target, source, and edge attribute\n",
    "        m_ij = torch.cat([x_i, x_j], dim=-1)\n",
    "        a_ij = self.edge_gate(edge_attr)\n",
    "\n",
    "        # Compute the edge message and apply activation\n",
    "        return self.activation(self.fc_message(m_ij)) * a_ij\n",
    "\n",
    "    def update(self, aggr_out):\n",
    "        \"\"\"\n",
    "        Update the node features by applying a fully connected layer on the aggregated messages.\n",
    "        \"\"\"\n",
    "        return self.fc_update(aggr_out)\n",
    "\n",
    "class ModalityToCellMP(MessagePassing):\n",
    "    def __init__(self, node_dim, cell_dim, hidden_cell_dim):\n",
    "        super(ModalityToCellMP, self).__init__(aggr='add')\n",
    "        self.cell_gate = nn.Sequential(\n",
    "            nn.Linear(cell_dim, cell_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(cell_dim, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.fc_message = nn.Linear(node_dim + cell_dim, hidden_cell_dim)\n",
    "        self.fc_update = nn.Linear(hidden_cell_dim, hidden_cell_dim)\n",
    "        self.activation = nn.SiLU()\n",
    "\n",
    "    def forward(self, x, c, edge_index):\n",
    "        return self.propagate(edge_index, x=x, c=c)\n",
    "\n",
    "    def message(self, c_i, x_j):\n",
    "        a = self.cell_gate(c_i)\n",
    "        m_ij = self.fc_message(torch.cat([x_j, c_i], dim=-1))\n",
    "        return self.activation(m_ij) * a\n",
    "\n",
    "    def update(self, aggr_out):\n",
    "        return self.fc_update(aggr_out)\n",
    "\n",
    "class MultiOmicsEmbedding(nn.Module):\n",
    "    def __init__(self, modality_in_dims, cell_in_dims, edge_attr_dims, modality_hidden_dims, modalities, cell_hidden_dims, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.activation = nn.SiLU()\n",
    "        self.modality_embs = nn.ModuleDict({\n",
    "            m: IntraModalityMP(\n",
    "                node_dim=modality_in_dims[m],\n",
    "                edge_attr_dim=edge_attr_dims[m],\n",
    "                hidden_dims=modality_hidden_dims,\n",
    "            ) for m in modalities\n",
    "        })\n",
    "        self.cell_emb = nn.Sequential(\n",
    "            Linear(cell_in_dims, cell_hidden_dims),\n",
    "            self.activation,\n",
    "        )\n",
    "\n",
    "    def forward(self, batch):\n",
    "\n",
    "        H = {}\n",
    "        for m in modalities:\n",
    "            H[m] = self.modality_embs[m](batch[m].x, batch[m, 'similar_to', m].edge_index, batch[m, 'similar_to', m].e)\n",
    "\n",
    "        C = self.cell_emb(batch['cell'].x)\n",
    "\n",
    "        return H, C\n",
    "\n",
    "class MultiOmicsLayer(nn.Module):\n",
    "    def __init__(self, modality_in_dims, cell_in_dims, edge_attr_dims, modality_hidden_dims, cell_hidden_dims, modalities, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.activation = nn.SiLU()\n",
    "        self.intra_modality_msg = nn.ModuleDict({\n",
    "            m: IntraModalityMP(\n",
    "                node_dim=modality_in_dims[m],\n",
    "                edge_attr_dim=edge_attr_dims[m],\n",
    "                hidden_dims=modality_hidden_dims,\n",
    "            ) for m in modalities\n",
    "        })\n",
    "\n",
    "        self.modality_to_cell_msg = nn.ModuleDict({\n",
    "            m: ModalityToCellMP(\n",
    "                node_dim=modality_hidden_dims,\n",
    "                cell_dim=cell_in_dims,\n",
    "                hidden_cell_dim=cell_hidden_dims,\n",
    "            ) for m in modalities\n",
    "        })\n",
    "\n",
    "    def forward(self, batch, H, C):\n",
    "\n",
    "        for m in modalities:\n",
    "            H[m] = H[m] + self.intra_modality_msg[m](H[m], batch[m, 'similar_to', m].edge_index, batch[m, 'similar_to', m].e)\n",
    "            C = C + self.modality_to_cell_msg[m](H[m], C, batch[m, 'belongs_to', 'cell'].edge_index)\n",
    "\n",
    "        return H, C\n",
    "\n",
    "class MultiOmicsIntegration(nn.Module):\n",
    "    def __init__(self, modality_in_dims, cell_in_dims, edge_attr_dims, modality_hidden_dims, cell_hidden_dims,\n",
    "                 modalities, layer_num=2, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        self.modality_in_dims = modality_in_dims\n",
    "        self.cell_in_dims = cell_in_dims\n",
    "        self.edge_attr_dims = edge_attr_dims\n",
    "        self.modality_hidden_dims = modality_hidden_dims\n",
    "        self.cell_hidden_dims = cell_hidden_dims\n",
    "        self.modalities = modalities\n",
    "        self.layer_num = layer_num\n",
    "\n",
    "        self.embedding = MultiOmicsEmbedding(\n",
    "            modality_in_dims=self.modality_in_dims,\n",
    "            cell_in_dims=self.cell_in_dims,\n",
    "            edge_attr_dims=self.edge_attr_dims,\n",
    "            modality_hidden_dims=self.modality_hidden_dims,\n",
    "            cell_hidden_dims=self.cell_hidden_dims,\n",
    "            modalities=self.modalities,\n",
    "        )\n",
    "\n",
    "        self.layers = nn.ModuleList([\n",
    "            MultiOmicsLayer(\n",
    "                modality_in_dims={m: self.modality_hidden_dims for m in self.modalities},\n",
    "                cell_in_dims=self.cell_hidden_dims,\n",
    "                edge_attr_dims=self.edge_attr_dims,\n",
    "                modality_hidden_dims=self.modality_hidden_dims,\n",
    "                cell_hidden_dims=self.cell_hidden_dims,\n",
    "                modalities=self.modalities\n",
    "            ) for _ in range(self.layer_num)\n",
    "        ])\n",
    "\n",
    "        self.modality_bn = nn.ModuleDict({\n",
    "            m: nn.BatchNorm1d(self.modality_hidden_dims) for m in self.modalities\n",
    "        })\n",
    "\n",
    "        self.cell_bn = nn.BatchNorm1d(self.cell_hidden_dims)\n",
    "\n",
    "    def normalize_each_modality(self, H):\n",
    "        for m in self.modalities:\n",
    "            H[m] = self.modality_bn[m](H[m])\n",
    "        return H\n",
    "\n",
    "    def forward(self, batch):\n",
    "        H, C = self.embedding(batch)\n",
    "        for layer in self.layers:\n",
    "            H, C = layer(batch, H, C)\n",
    "            H = self.normalize_each_modality(H)\n",
    "            C = self.cell_bn(C)\n",
    "\n",
    "        return H, C\n",
    "\n",
    "model = MultiOmicsIntegration(\n",
    "    modality_in_dims={m: data[m].x.shape[1] for m in modalities},\n",
    "    edge_attr_dims={m: data[m, 'similar_to', m].e.shape[1] for m in modalities},\n",
    "    cell_in_dims=data['cell'].x.shape[1],\n",
    "    cell_hidden_dims=256,\n",
    "    modality_hidden_dims=64,\n",
    "    modalities=modalities,\n",
    ").to(device)\n",
    "\n",
    "\n",
    "\n",
    "batch = model(next(iter(sampler)).to(device))\n",
    "batch\n"
   ],
   "id": "aefbbe55ac9f1aed",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'adt': tensor([[ 2.3311,  0.5682, -0.4285,  ...,  2.4638, -1.0885, -0.8179],\n",
       "          [ 1.0701, -4.5158,  0.0322,  ...,  1.1128,  0.3254,  1.8957],\n",
       "          [ 0.5050, -0.3739,  1.6729,  ...,  2.5747, -0.6587, -2.3867],\n",
       "          ...,\n",
       "          [-0.1301,  0.1298,  0.0759,  ..., -0.1524,  0.3059, -0.1478],\n",
       "          [-0.1301,  0.1298,  0.0759,  ..., -0.1524,  0.3059, -0.1478],\n",
       "          [-0.1301,  0.1298,  0.0759,  ..., -0.1524,  0.3059, -0.1478]],\n",
       "         device='cuda:0', grad_fn=<NativeBatchNormBackward0>),\n",
       "  'RNA': tensor([[ 0.3337, -0.4875, -0.3552,  ..., -0.5535,  0.2425, -0.0739],\n",
       "          [ 2.4849, -2.7782,  2.1306,  ..., -2.5821,  0.8290, -0.4272],\n",
       "          [-0.1772,  0.2140, -0.3553,  ...,  0.1153, -0.0359,  0.0949],\n",
       "          ...,\n",
       "          [-0.0039, -0.0275, -0.2441,  ...,  0.0126, -0.3625, -0.1814],\n",
       "          [-0.0039, -0.0275, -0.2441,  ...,  0.0126, -0.3625, -0.1814],\n",
       "          [-0.0039, -0.0275, -0.2441,  ...,  0.0126, -0.3625, -0.1814]],\n",
       "         device='cuda:0', grad_fn=<NativeBatchNormBackward0>),\n",
       "  'atac': tensor([[-0.9711,  0.9708,  0.1667,  ...,  0.6349,  0.1297, -0.7807],\n",
       "          [ 0.0119,  0.6278,  0.2605,  ..., -0.1290,  0.1126, -0.1061],\n",
       "          [ 0.3698, -0.1002,  0.0115,  ...,  0.3827, -0.4362, -0.3385],\n",
       "          ...,\n",
       "          [-0.0614,  0.0208, -0.0883,  ..., -0.1885,  0.0809,  0.1234],\n",
       "          [-0.0614,  0.0208, -0.0883,  ..., -0.1885,  0.0809,  0.1234],\n",
       "          [-0.0614,  0.0208, -0.0883,  ..., -0.1885,  0.0809,  0.1234]],\n",
       "         device='cuda:0', grad_fn=<NativeBatchNormBackward0>)},\n",
       " tensor([[ 0.1934, -0.3622, -0.5724,  ...,  0.7093,  0.2394, -0.4867],\n",
       "         [ 0.4598,  0.0696, -0.8265,  ...,  0.4481,  0.3832, -0.2031],\n",
       "         [-0.4087, -0.0132, -0.1981,  ...,  0.3580, -0.1540, -0.2620],\n",
       "         ...,\n",
       "         [-0.3766, -0.0842, -0.2364,  ..., -0.4619,  0.5911, -0.3315],\n",
       "         [-0.2199, -0.3623, -0.0785,  ..., -0.3670, -0.0924, -0.2807],\n",
       "         [-0.1592, -0.3028, -0.1324,  ...,  0.2118, -0.1867, -0.1110]],\n",
       "        device='cuda:0', grad_fn=<NativeBatchNormBackward0>))"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 114
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T14:38:37.837036Z",
     "start_time": "2025-03-08T14:38:37.690215Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Define the decoder.\n",
    "# ------------------------------------------------------------------------------\n",
    "class MultiOmicsDecoder(nn.Module):\n",
    "    def __init__(self, encoder, modality_in_dims, cell_in_dims, modalities):\n",
    "        super().__init__()\n",
    "        self.modalities = modalities\n",
    "\n",
    "        # For each modality, define a decoder mapping from latent dim back to the original feature dim.\n",
    "        self.modality_decoders = nn.ModuleDict({\n",
    "            m: nn.Sequential(\n",
    "                nn.Linear(encoder.modality_hidden_dims, modality_in_dims[m]),\n",
    "                nn.SiLU(),  # optional non-linearity; adjust as needed\n",
    "            )\n",
    "            for m in modalities\n",
    "        })\n",
    "\n",
    "        # Decoder for cell nodes.\n",
    "        self.cell_decoder = nn.Sequential(\n",
    "            nn.Linear(encoder.cell_hidden_dims, cell_in_dims),\n",
    "            nn.SiLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, H, C):\n",
    "        modality_recons = {m: self.modality_decoders[m](H[m]) for m in self.modalities}\n",
    "        cell_recon = self.cell_decoder(C)\n",
    "        return modality_recons, cell_recon\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Define a separate noising function.\n",
    "# This function adds noise only once per batch when called.\n",
    "# ------------------------------------------------------------------------------\n",
    "def add_noise(batch, modalities, noise_std=0.1, drop_modality_prob=0.5):\n",
    "    \"\"\"\n",
    "    Adds noise to the input batch.\n",
    "      - For each modality, adds Gaussian noise.\n",
    "      - With some probability, drops a modality (zeroes its features).\n",
    "      - Also adds noise to cell node features.\n",
    "    \"\"\"\n",
    "    noisy_batch = copy.deepcopy(batch)\n",
    "    noise_mask = torch.rand(noisy_batch['cell'].x.shape[0]) > 0.1\n",
    "\n",
    "    # Process each modality.\n",
    "    for m in modalities:\n",
    "        if 'x' in noisy_batch[m]:\n",
    "            original = noisy_batch[m].x[noise_mask]\n",
    "            if torch.rand(1).item() < drop_modality_prob:\n",
    "                # Drop modality: replace with pure noise.\n",
    "                noisy_batch[m].x[noise_mask] = noise_std * torch.randn_like(original)\n",
    "            else:\n",
    "                # Add Gaussian noise.\n",
    "                noisy_batch[m].x[noise_mask] = original + noise_std * torch.randn_like(original)\n",
    "\n",
    "    # Add noise to cell features.\n",
    "    if 'x' in noisy_batch['cell']:\n",
    "        original = noisy_batch['cell'].x[noise_mask]\n",
    "        noisy_batch['cell'].x[noise_mask] = original + noise_std * torch.randn_like(original)\n",
    "\n",
    "    return noisy_batch\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Example usage.\n",
    "# ------------------------------------------------------------------------------\n",
    "# Assume you have:\n",
    "# - `data`: a dict-like heterogeneous graph with keys for each modality and 'cell'\n",
    "# - `modalities`: list of modality names (e.g. ['RNA', 'adt', 'atac'])\n",
    "# - `sampler`: an iterable over batches\n",
    "# - `device`: torch device (e.g. 'cuda' or 'cpu')\n",
    "\n",
    "# Instantiate the encoder.\n",
    "encoder = MultiOmicsIntegration(\n",
    "    modality_in_dims={m: data[m].x.shape[1] for m in modalities},\n",
    "    edge_attr_dims={m: data[m, 'similar_to', m].e.shape[1] for m in modalities},\n",
    "    cell_in_dims=data['cell'].x.shape[1],\n",
    "    cell_hidden_dims=256,\n",
    "    modality_hidden_dims=64,\n",
    "    modalities=modalities,\n",
    ").to(device)\n",
    "\n",
    "# Instantiate the decoder.\n",
    "decoder = MultiOmicsDecoder(\n",
    "    encoder=encoder,\n",
    "    modality_in_dims={m: data[m].x.shape[1] for m in modalities},\n",
    "    cell_in_dims=data['cell'].x.shape[1],\n",
    "    modalities=modalities,\n",
    ").to(device)\n",
    "\n",
    "# Define optimizer over the parameters of both encoder and decoder.\n",
    "optimizer = torch.optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr=1e-4)\n",
    "\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    for batch in tqdm(sampler):\n",
    "        # Move batch to device.\n",
    "        batch = batch.to(device)\n",
    "\n",
    "        # Apply noise once to the input batch.\n",
    "        noisy_batch = add_noise(batch, modalities, noise_std=0.1, drop_modality_prob=0.003)\n",
    "\n",
    "        # Zero gradients.\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass: encode then decode.\n",
    "        H, C = encoder(noisy_batch)\n",
    "        modality_recons, cell_recon = decoder(H, C)\n",
    "\n",
    "        # Compute reconstruction losses, e.g. using MSE.\n",
    "        loss_modality = sum(F.mse_loss(modality_recons[m], batch[m].x) for m in modalities)\n",
    "        loss_cell = F.mse_loss(cell_recon, batch['cell'].x)\n",
    "        loss = loss_modality + loss_cell\n",
    "\n",
    "        # Backward pass.\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # (Optional) Evaluate reconstruction loss at end of epoch.\n",
    "    H, C = encoder(noisy_batch)\n",
    "    modality_recons, cell_recon = decoder(H, C)\n",
    "    loss_modality = sum(F.mse_loss(modality_recons[m], batch[m].x) for m in modalities)\n",
    "    loss_cell = F.mse_loss(cell_recon, batch['cell'].x)\n",
    "    loss = loss_modality + loss_cell\n",
    "    print(f\"Epoch {epoch + 1} Reconstruction loss: {loss.item()}\")\n"
   ],
   "id": "d400fa1dc6466625",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "The shape of the mask [10881] at index 0 does not match the shape of the indexed tensor [10066, 100] at index 0",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[117], line 104\u001B[0m\n\u001B[0;32m    101\u001B[0m batch \u001B[38;5;241m=\u001B[39m batch\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m    103\u001B[0m \u001B[38;5;66;03m# Apply noise once to the input batch.\u001B[39;00m\n\u001B[1;32m--> 104\u001B[0m noisy_batch \u001B[38;5;241m=\u001B[39m add_noise(batch, modalities, noise_std\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.1\u001B[39m, drop_modality_prob\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.003\u001B[39m)\n\u001B[0;32m    106\u001B[0m \u001B[38;5;66;03m# Zero gradients.\u001B[39;00m\n\u001B[0;32m    107\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n",
      "Cell \u001B[1;32mIn[117], line 52\u001B[0m, in \u001B[0;36madd_noise\u001B[1;34m(batch, modalities, noise_std, drop_modality_prob)\u001B[0m\n\u001B[0;32m     50\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m m \u001B[38;5;129;01min\u001B[39;00m modalities:\n\u001B[0;32m     51\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mx\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m noisy_batch[m]:\n\u001B[1;32m---> 52\u001B[0m         original \u001B[38;5;241m=\u001B[39m noisy_batch[m]\u001B[38;5;241m.\u001B[39mx[noise_mask]\n\u001B[0;32m     53\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mrand(\u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m.\u001B[39mitem() \u001B[38;5;241m<\u001B[39m drop_modality_prob:\n\u001B[0;32m     54\u001B[0m             \u001B[38;5;66;03m# Drop modality: replace with pure noise.\u001B[39;00m\n\u001B[0;32m     55\u001B[0m             noisy_batch[m]\u001B[38;5;241m.\u001B[39mx[noise_mask] \u001B[38;5;241m=\u001B[39m noise_std \u001B[38;5;241m*\u001B[39m torch\u001B[38;5;241m.\u001B[39mrandn_like(original)\n",
      "\u001B[1;31mIndexError\u001B[0m: The shape of the mask [10881] at index 0 does not match the shape of the indexed tensor [10066, 100] at index 0"
     ]
    }
   ],
   "execution_count": 117
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": " seq -> cell -> cell sim",
   "id": "1f34de9721017373"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T17:02:34.098724Z",
     "start_time": "2025-03-07T17:02:34.086917Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "torch.topk(torch.tensor(X[modalities[0]]), k=10, dim=1).indices"
   ],
   "id": "af50ed631cc1575f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 74, 109,  96,  ...,  51, 192, 159],\n",
       "        [ 27, 158,  57,  ..., 139, 122, 209],\n",
       "        [122,  94, 175,  ...,  58,  53,   6],\n",
       "        ...,\n",
       "        [196,  34, 123,  ...,  31,  76, 109],\n",
       "        [ 27,  26,  79,  ..., 161,  70, 165],\n",
       "        [158, 132, 195,  ...,  21,  97, 166]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T17:17:17.727706Z",
     "start_time": "2025-03-07T17:16:27.869628Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import toponetx as tnx\n",
    "from toponetx.classes.combinatorial_complex import CombinatorialComplex\n",
    "\n",
    "offsets = [0] * len(modalities)\n",
    "for idx, m in enumerate(modalities[1:]):\n",
    "    offsets[idx + 1] = offsets[idx] + X[m].shape[1]\n",
    "\n",
    "ccc: CombinatorialComplex = CombinatorialComplex()\n",
    "cell = torch.cat([\n",
    "    torch.topk(torch.tensor(X[m]), k=10, dim=1).indices + offset\n",
    "    for offset, m in zip(offsets, modalities)\n",
    "], dim=1)\n",
    "\n",
    "ccc.add_cells_from(range(cell.shape[0]), ranks=0)\n",
    "ccc.add_cells_from(cell.detach().cpu().numpy(), ranks=1)\n",
    "\n",
    "ccc.number_of_cells()"
   ],
   "id": "42321ca5f224c2a9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27526"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T17:11:53.120767Z",
     "start_time": "2025-03-07T17:11:53.116763Z"
    }
   },
   "cell_type": "code",
   "source": "ccc.skeleton(rank=0)[-1]",
   "id": "c1f587288d7b23d9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frozenset({13762})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T17:12:34.309112Z",
     "start_time": "2025-03-07T17:12:34.304652Z"
    }
   },
   "cell_type": "code",
   "source": "cell.max()",
   "id": "231509dbfacdd20d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9789)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T17:16:08.535451Z",
     "start_time": "2025-03-07T17:16:08.531413Z"
    }
   },
   "cell_type": "code",
   "source": [
    "offsets = [0] * len(modalities)\n",
    "for idx, m in enumerate(modalities[1:]):\n",
    "    offsets[idx + 1] = offsets[idx] + X[m].shape[1]\n",
    "offsets"
   ],
   "id": "c5cb7d5593e3f19",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 3000, 8000]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "dad67078307efc88"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
